# ğŸš€ Pipeline AutomatisÃ© MLOps - Configuration ComplÃ¨te

## âœ… Ce qui a Ã©tÃ© crÃ©Ã©

J'ai mis en place un pipeline automatisÃ© complet qui:

1. **DÃ©tecte automatiquement les changements DVC** (nouvelles donnÃ©es)
2. **ExÃ©cute le pipeline DVC** (prepare_data â†’ train â†’ evaluate â†’ export)
3. **Enregistre les donnÃ©es et modÃ¨les dans MLflow**
4. **Reconstruit l'image Docker** avec le nouveau modÃ¨le
5. **RedÃ©ploie localement** avec Docker Compose

## ğŸ“ Fichiers crÃ©Ã©s

### Scripts principaux

1. **`scripts/monitor_dvc_changes.py`**
   - Surveille les changements dans `dvc.lock` et fichiers `.dvc`
   - DÃ©tecte quand de nouvelles donnÃ©es sont ajoutÃ©es
   - Peut fonctionner en mode surveillance continue

2. **`scripts/run_automated_pipeline.py`**
   - Script principal qui orchestre tout le pipeline
   - ExÃ©cute toutes les Ã©tapes automatiquement
   - GÃ¨re les erreurs et affiche un rÃ©sumÃ©

3. **`scripts/watch_and_trigger.py`**
   - Surveillance continue avec dÃ©clenchement automatique
   - VÃ©rifie les changements toutes les 30 secondes (configurable)
   - DÃ©clenche le pipeline dÃ¨s qu'un changement est dÃ©tectÃ©

4. **`scripts/quick_start.sh`** et **`scripts/quick_start.ps1`**
   - Scripts de dÃ©marrage rapide pour Linux/Mac et Windows
   - VÃ©rifient les prÃ©requis
   - Interface simple pour choisir l'option

### Documentation

- **`scripts/AUTOMATED_PIPELINE_README.md`** - Guide complet d'utilisation

### Modifications

- **`docker/docker-compose.yml`** - Service API ajoutÃ© et configurÃ©
- **`src/train.py`** - AmÃ©lioration de l'enregistrement des donnÃ©es dans MLflow

## ğŸš€ Utilisation rapide

### Option 1: ExÃ©cution manuelle unique

```bash
# ExÃ©cuter le pipeline une fois
python scripts/run_automated_pipeline.py

# Forcer mÃªme sans changements
python scripts/run_automated_pipeline.py --force
```

### Option 2: Surveillance continue (recommandÃ©)

```bash
# DÃ©marrer la surveillance (dÃ©clenchement automatique)
python scripts/watch_and_trigger.py

# Avec intervalle personnalisÃ© (60 secondes)
python scripts/watch_and_trigger.py --interval 60
```

### Option 3: Script de dÃ©marrage rapide

**Linux/Mac:**
```bash
bash scripts/quick_start.sh
```

**Windows:**
```powershell
.\scripts\quick_start.ps1
```

## ğŸ“Š Flux de travail

```
1. Ajouter nouvelles donnÃ©es
   â†“
   dvc add data/raw/PlantVillage/NewClass
   git add data/raw/PlantVillage/NewClass.dvc dvc.lock
   git commit -m "Add new data"
   
2. Pipeline dÃ©tecte automatiquement (si surveillance active)
   OU
   ExÃ©cuter manuellement: python scripts/run_automated_pipeline.py
   
3. Pipeline exÃ©cute:
   - dvc repro (prepare_data â†’ train â†’ evaluate â†’ export)
   - Enregistrement dans MLflow
   - Construction Docker
   - DÃ©ploiement local
   
4. API disponible avec nouveau modÃ¨le
   http://localhost:8000
```

## ğŸ”§ Configuration

Le pipeline utilise `config.yaml` pour:
- Chemins des donnÃ©es et modÃ¨les
- Configuration MLflow (tracking_uri, experiment_name)
- Configuration Docker (image_name, tag)
- ParamÃ¨tres d'entraÃ®nement

## ğŸ“ Exemple complet

### 1. DÃ©marrer la surveillance

```bash
# Terminal 1
python scripts/watch_and_trigger.py
```

### 2. Ajouter de nouvelles donnÃ©es

```bash
# Terminal 2
# Ajouter de nouvelles images dans data/raw/PlantVillage/NewClass/

# Ajouter Ã  DVC
dvc add data/raw/PlantVillage/NewClass

# Commit
git add data/raw/PlantVillage/NewClass.dvc dvc.lock
git commit -m "Add new plant disease class"
```

### 3. Le pipeline se dÃ©clenche automatiquement!

Dans le Terminal 1, vous verrez:
```
ğŸ” VÃ©rification #1...
ğŸ” Changements DVC dÃ©tectÃ©s!
ğŸ”„ CHANGEMENTS DÃ‰TECTÃ‰S - DÃ‰CLENCHEMENT DU PIPELINE
ğŸš€ ExÃ©cution du pipeline DVC...
âœ… Pipeline DVC exÃ©cutÃ© avec succÃ¨s
ğŸ“ VÃ©rification de l'enregistrement MLflow...
âœ… ModÃ¨le de production trouvÃ©
ğŸ³ Reconstruction de l'image Docker...
âœ… Image Docker construite avec succÃ¨s
ğŸš€ DÃ©ploiement local avec Docker Compose...
âœ… Services dÃ©ployÃ©s avec succÃ¨s
ğŸ‰ PIPELINE TERMINÃ‰ AVEC SUCCÃˆS!
```

### 4. Tester la nouvelle API

```bash
curl http://localhost:8000/health
curl -X POST http://localhost:8000/predict -F "file=@test_image.jpg"
```

## ğŸ¯ Services disponibles aprÃ¨s dÃ©ploiement

- **API**: http://localhost:8000
  - `/docs` - Documentation Swagger
  - `/health` - Health check
  - `/predict` - PrÃ©diction
  - `/metrics` - MÃ©triques Prometheus

- **MLflow**: http://localhost:5000
  - ExpÃ©riences et runs
  - Model Registry
  - MÃ©triques et graphiques

- **Grafana**: http://localhost:3000 (admin/admin)
  - Dashboards de monitoring

- **Prometheus**: http://localhost:9091
  - MÃ©triques brutes

## ğŸ› DÃ©pannage

### Le pipeline ne dÃ©tecte pas les changements

```bash
# VÃ©rifier manuellement
python scripts/monitor_dvc_changes.py

# Forcer l'exÃ©cution
python scripts/run_automated_pipeline.py --force
```

### Erreur DVC

```bash
# VÃ©rifier le statut
dvc status

# ExÃ©cuter manuellement
dvc repro
```

### Erreur Docker

```bash
# VÃ©rifier que le modÃ¨le existe
ls -lh models/production/model.ckpt

# Construire manuellement
docker build -f docker/Dockerfile.inference -t plant-disease-mlops:latest .
```

### L'API ne dÃ©marre pas

```bash
# VÃ©rifier les logs
docker-compose -f docker/docker-compose.yml logs plant-disease-api

# RedÃ©marrer
docker-compose -f docker/docker-compose.yml restart plant-disease-api
```

## ğŸ“š Documentation complÃ¨te

Consultez `scripts/AUTOMATED_PIPELINE_README.md` pour:
- Guide dÃ©taillÃ© de chaque Ã©tape
- Options avancÃ©es
- Configuration personnalisÃ©e
- Workflows complexes

## âœ… Checklist de vÃ©rification

Avant d'utiliser le pipeline:

- [ ] DVC installÃ© et initialisÃ© (`dvc init`)
- [ ] Docker et Docker Compose installÃ©s
- [ ] MLflow accessible (dÃ©marre avec docker-compose)
- [ ] DonnÃ©es dans `data/raw/PlantVillage/`
- [ ] `config.yaml` configurÃ© correctement
- [ ] DÃ©pendances Python installÃ©es (`pip install -r requirements.txt`)

## ğŸ‰ PrÃªt Ã  utiliser!

Le pipeline est maintenant complÃ¨tement automatisÃ©. Il suffit de:

1. **DÃ©marrer la surveillance**: `python scripts/watch_and_trigger.py`
2. **Ajouter de nouvelles donnÃ©es** avec DVC
3. **Le pipeline se dÃ©clenche automatiquement!**

Tout est enregistrÃ© dans MLflow et l'API est redÃ©ployÃ©e avec le nouveau modÃ¨le.

---

**ğŸ’¡ Astuce**: Pour un premier test, utilisez `--force` pour exÃ©cuter le pipeline mÃªme sans changements DVC.

