# ğŸ“ Guide de PrÃ©sentation - Pipeline MLOps
## DÃ©tection de Maladies de Plantes

> **Document destinÃ© Ã  la soutenance PFA**  
> PrÃ©parÃ© pour dÃ©monstration devant l'encadrant

---

## ğŸ“‹ Table des MatiÃ¨res

1. [Vue d'ensemble du projet](#1-vue-densemble-du-projet)
2. [Architecture MLOps](#2-architecture-mlops)
3. [DÃ©monstration pas Ã  pas](#3-dÃ©monstration-pas-Ã -pas)
4. [Points clÃ©s Ã  prÃ©senter](#4-points-clÃ©s-Ã -prÃ©senter)
5. [Commandes de dÃ©monstration](#5-commandes-de-dÃ©monstration)
6. [FAQ pour la soutenance](#6-faq-pour-la-soutenance)

---

## 1. Vue d'ensemble du projet

### ğŸ¯ ProblÃ©matique
> "Comment concevoir un pipeline MLOps capable d'entraÃ®ner, dÃ©ployer et surveiller automatiquement un modÃ¨le de dÃ©tection de maladies vÃ©gÃ©tales, tout en assurant la reproductibilitÃ© et la scalabilitÃ© du systÃ¨me ?"

### âœ… Solution implÃ©mentÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE MLOPS COMPLET                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  ğŸ“Š DataOps          ğŸ¤– ModelOps          ğŸš€ DeploymentOps          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚  â€¢ DVC               â€¢ PyTorch Lightning â€¢ Docker                   â”‚
â”‚  â€¢ Augmentation      â€¢ MLflow Tracking   â€¢ Kubernetes               â”‚
â”‚  â€¢ Versioning        â€¢ Model Registry    â€¢ GitHub Actions           â”‚
â”‚                      â€¢ ONNX Export       â€¢ Prometheus/Grafana       â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Architecture MLOps

### ğŸ“ Diagramme d'Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dataset    â”‚â”€â”€â”€â”€â–¶â”‚     DVC      â”‚â”€â”€â”€â”€â–¶â”‚  Processed   â”‚
â”‚ PlantVillage â”‚     â”‚  Versioning  â”‚     â”‚    Data      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MLflow     â”‚â—€â”€â”€â”€â”€â”‚   Training   â”‚â—€â”€â”€â”€â”€â”‚   PyTorch    â”‚
â”‚   Tracking   â”‚     â”‚   Pipeline   â”‚     â”‚  Lightning   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Model     â”‚â”€â”€â”€â”€â–¶â”‚    Docker    â”‚â”€â”€â”€â”€â–¶â”‚  Kubernetes  â”‚
â”‚   Registry   â”‚     â”‚    Image     â”‚     â”‚  Deployment  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI    â”‚â”€â”€â”€â”€â–¶â”‚  Prometheus  â”‚â”€â”€â”€â”€â–¶â”‚   Grafana    â”‚
â”‚     API      â”‚     â”‚   Metrics    â”‚     â”‚  Dashboard   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ Structure du Projet

```
Pipeline-MLOps/
â”œâ”€â”€ ğŸ“‚ src/                    # Code source principal
â”‚   â”œâ”€â”€ api.py                 # API FastAPI avec Prometheus
â”‚   â”œâ”€â”€ train.py               # Script d'entraÃ®nement + MLflow
â”‚   â”œâ”€â”€ models.py              # CNN & ViT avec PyTorch Lightning
â”‚   â””â”€â”€ data_preprocessing.py  # Augmentation avec Albumentations
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                # Scripts MLOps
â”‚   â”œâ”€â”€ prepare_data.py        # PrÃ©paration donnÃ©es (DVC)
â”‚   â”œâ”€â”€ evaluate.py            # Ã‰valuation (F1, ROC, Confusion)
â”‚   â”œâ”€â”€ export_model.py        # Export ONNX + Registry
â”‚   â””â”€â”€ drift_analysis.py      # DÃ©tection drift (Evidently)
â”‚
â”œâ”€â”€ ğŸ“‚ docker/                 # Conteneurisation
â”‚   â”œâ”€â”€ Dockerfile.inference   # Image optimisÃ©e production
â”‚   â””â”€â”€ docker-compose.yml     # Stack complÃ¨te locale
â”‚
â”œâ”€â”€ ğŸ“‚ k8s/                    # Orchestration Kubernetes
â”‚   â”œâ”€â”€ deployment.yaml        # DÃ©ploiement avec replicas
â”‚   â”œâ”€â”€ service.yaml           # LoadBalancer
â”‚   â””â”€â”€ hpa.yaml              # Auto-scaling
â”‚
â”œâ”€â”€ ğŸ“‚ .github/workflows/      # CI/CD
â”‚   â””â”€â”€ mlops-pipeline.yml     # Pipeline complet
â”‚
â”œâ”€â”€ ğŸ“‚ monitoring/             # ObservabilitÃ©
â”‚   â”œâ”€â”€ prometheus.yml         # Config Prometheus
â”‚   â””â”€â”€ grafana/              # Dashboards
â”‚
â”œâ”€â”€ ğŸ“„ dvc.yaml                # Pipeline DVC
â”œâ”€â”€ ğŸ“„ config.yaml             # Configuration centralisÃ©e
â””â”€â”€ ğŸ“„ requirements.txt        # DÃ©pendances
```

---

## 3. DÃ©monstration pas Ã  pas

### ğŸ”§ PrÃ©requis (Ã  installer avant la dÃ©mo)

```powershell
# 1. Installer Python 3.10+ depuis python.org
# 2. DÃ©marrer Docker Desktop
# 3. Installer les dÃ©pendances
pip install -r requirements.txt
```

### ğŸ“Š DÃ©mo 1: Pipeline DVC (DataOps)

```powershell
# Montrer le fichier dvc.yaml
cat dvc.yaml

# ExÃ©cuter la prÃ©paration des donnÃ©es
python scripts/prepare_data.py --config config.yaml

# Visualiser le pipeline
dvc dag
```

**Points Ã  expliquer:**
- Versioning des donnÃ©es avec DVC
- ReproductibilitÃ© des expÃ©riences
- Division 70/20/10 (train/val/test)

### ğŸ¤– DÃ©mo 2: EntraÃ®nement avec MLflow (ModelOps)

```powershell
# DÃ©marrer MLflow UI (dans un terminal sÃ©parÃ©)
mlflow ui --port 5000

# Lancer l'entraÃ®nement
python src/train.py --model cnn --dataset data/raw/PlantVillage --config config.yaml
```

**Points Ã  expliquer:**
- Tracking automatique des mÃ©triques
- Logging des hyperparamÃ¨tres
- Model Registry pour versioning

### ğŸš€ DÃ©mo 3: API FastAPI (DeploymentOps)

```powershell
# Lancer l'API localement
python src/api.py

# Dans un autre terminal, tester l'API
curl http://localhost:8000/health
curl http://localhost:8000/classes
```

**Points Ã  expliquer:**
- Endpoint /predict pour l'infÃ©rence
- MÃ©triques Prometheus automatiques
- Temps de rÃ©ponse < 2s

### ğŸ³ DÃ©mo 4: Docker & Kubernetes

```powershell
# Build de l'image Docker
docker build -f docker/Dockerfile.inference -t plant-disease-api .

# Lancer avec Docker
docker run -p 8000:8000 plant-disease-api

# Voir les manifests Kubernetes
cat k8s/deployment.yaml
cat k8s/hpa.yaml
```

**Points Ã  expliquer:**
- Image optimisÃ©e pour production
- Auto-scaling avec HPA
- Health checks et readiness probes

### ğŸ“ˆ DÃ©mo 5: Monitoring

```powershell
# Lancer la stack de monitoring
docker-compose -f docker/docker-compose.yml up -d

# AccÃ©der aux interfaces
# Grafana: http://localhost:3000 (admin/admin)
# Prometheus: http://localhost:9091
# MLflow: http://localhost:5000
```

---

## 4. Points clÃ©s Ã  prÃ©senter

### âœ… ConformitÃ© au Cahier des Charges

| Exigence | ImplÃ©mentation | Fichier |
|----------|---------------|---------|
| DVC - Gestion donnÃ©es | âœ… Pipeline 5 stages | `dvc.yaml` |
| MLflow - Tracking | âœ… MÃ©triques + Registry | `src/train.py` |
| CNN/ViT | âœ… ResNet50, EfficientNet | `src/models.py` |
| FastAPI | âœ… /predict, /health | `src/api.py` |
| Docker | âœ… Multi-stage build | `docker/Dockerfile.inference` |
| Kubernetes | âœ… Deployment + HPA | `k8s/` |
| CI/CD | âœ… GitHub Actions | `.github/workflows/` |
| Prometheus | âœ… Instrumentator | `src/api.py` |
| Grafana | âœ… Dashboard custom | `monitoring/grafana/` |
| Evidently | âœ… Drift detection | `scripts/drift_analysis.py` |
| Tests | âœ… Unit + API | `tests/` |

### ğŸ¯ MÃ©triques Attendues

- **Accuracy modÃ¨le**: 90-95%
- **F1-Score**: > 0.90
- **Temps infÃ©rence**: < 100ms
- **Temps rÃ©ponse API**: < 2s
- **DisponibilitÃ©**: 99.9% (avec replicas K8s)

---

## 5. Commandes de dÃ©monstration

### ğŸš€ Scripts Bash disponibles

Tous les scripts sont dans le dossier `scripts/` et utilisent des chemins relatifs.

#### Script principal (menu interactif)
```bash
cd scripts
./main.sh                    # Afficher le menu complet
./main.sh pipeline          # Lancer le pipeline complet
./main.sh api               # Lancer l'API
./main.sh monitoring        # DÃ©marrer le monitoring
./main.sh tests             # Lancer tous les tests
./main.sh demo              # PrÃ©sentation interactive
```

#### Pipeline MLOps complet
```bash
cd scripts

# VÃ©rifier les prÃ©requis
./run_pipeline.sh check

# Installer les dÃ©pendances
./run_pipeline.sh install

# Initialiser DVC
./run_pipeline.sh init

# ExÃ©cuter le pipeline complet (5 Ã©tapes)
./run_pipeline.sh pipeline

# Lancer les tests
./run_pipeline.sh test

# Construire les images Docker
./run_pipeline.sh docker

# Tout faire automatiquement
./run_pipeline.sh all
```

#### API FastAPI
```bash
cd scripts

# Mode dÃ©veloppement (avec rechargement auto)
./run_api.sh dev

# Mode production (recommandÃ©)
./run_api.sh gunicorn

# Tester l'API automatiquement
./run_api.sh test
```

#### Monitoring Prometheus + Grafana
```bash
cd scripts

# DÃ©marrer la stack de monitoring
./run_monitoring.sh start

# VÃ©rifier le statut
./run_monitoring.sh status

# Tester les services
./run_monitoring.sh test

# Afficher les logs
./run_monitoring.sh logs
```

#### Tests automatisÃ©s
```bash
cd scripts

# Tests unitaires avec couverture
./run_tests.sh unit

# Tests d'intÃ©gration API
./run_tests.sh api

# Tests de performance
./run_tests.sh perf

# Tests de sÃ©curitÃ©
./run_tests.sh security

# Tests du pipeline DVC
./run_tests.sh pipeline

# Tous les tests
./run_tests.sh all

# GÃ©nÃ©rer un rapport
./run_tests.sh report
```

#### DÃ©ploiement Kubernetes
```bash
cd scripts

# VÃ©rifier les prÃ©requis
./deploy_k8s.sh check

# Construire et pousser les images
./deploy_k8s.sh build

# DÃ©ploiement complet
./deploy_k8s.sh deploy

# Tester le dÃ©ploiement
./deploy_k8s.sh test

# Afficher le statut
./deploy_k8s.sh status
```

#### DÃ©monstration interactive
```bash
cd scripts

# PrÃ©sentation complÃ¨te du projet
./demo_presentation.sh
```

### ğŸ“‹ URLs importantes

AprÃ¨s avoir lancÃ© les services :

- **API FastAPI**: http://localhost:8000
- **Documentation API**: http://localhost:8000/docs
- **MÃ©triques Prometheus**: http://localhost:8000/metrics
- **Grafana**: http://localhost:3000 (admin/admin)
- **Prometheus**: http://localhost:9091
- **MLflow**: http://localhost:5000

### ğŸ¯ Workflow de dÃ©monstration recommandÃ©

```bash
# 1. VÃ©rification du projet
cd scripts && ./run_pipeline.sh check

# 2. Pipeline complet
./run_pipeline.sh all

# 3. Lancement de l'API
./run_api.sh gunicorn &

# 4. DÃ©marrage du monitoring
./run_monitoring.sh start

# 5. Tests complets
./run_tests.sh all

# 6. PrÃ©sentation finale
./demo_presentation.sh
```

---

## 6. FAQ pour la soutenance

### Q1: "Pourquoi DVC plutÃ´t que Git LFS?"
> DVC permet de crÃ©er des pipelines reproductibles avec des dÃ©pendances explicites entre les Ã©tapes. Il gÃ¨re aussi le versioning des donnÃ©es volumineuses avec des backends cloud (S3, GCS).

### Q2: "Comment gÃ©rez-vous le drift des donnÃ©es?"
> Nous utilisons Evidently AI pour dÃ©tecter automatiquement les dÃ©rives de distribution entre les donnÃ©es d'entraÃ®nement et de production. Le script `drift_analysis.py` gÃ©nÃ¨re des rapports HTML.

### Q3: "Quelle est la stratÃ©gie de dÃ©ploiement?"
> DÃ©ploiement blue-green via Kubernetes avec:
> - Rolling updates pour zÃ©ro downtime
> - HPA pour auto-scaling (2-10 replicas)
> - Health checks pour haute disponibilitÃ©

### Q4: "Comment assurez-vous la reproductibilitÃ©?"
> - DVC pour le versioning des donnÃ©es
> - MLflow pour le tracking des expÃ©riences
> - Docker pour l'environnement
> - Config centralisÃ©e dans `config.yaml`

### Q5: "Quelles mÃ©triques surveillez-vous en production?"
> - Latence API (p50, p95, p99)
> - Taux de requÃªtes (QPS)
> - Distribution de confiance des prÃ©dictions
> - CPU/MÃ©moire des pods Kubernetes

---

## ğŸ“Š Slides suggÃ©rÃ©es pour la prÃ©sentation

1. **Introduction** (2 min)
   - Contexte agriculture + IA
   - ProblÃ©matique

2. **Ã‰tat de l'art** (3 min)
   - CNN vs ViT
   - Outils MLOps

3. **Architecture** (5 min)
   - Diagramme pipeline
   - Choix technologiques

4. **DÃ©monstration** (10 min)
   - DVC pipeline
   - MLflow tracking
   - API FastAPI
   - Monitoring

5. **RÃ©sultats** (3 min)
   - MÃ©triques modÃ¨le
   - Performance API

6. **Conclusion** (2 min)
   - Objectifs atteints
   - Perspectives

---

## ğŸš¦ Checklist avant la dÃ©mo

- [ ] Python 3.10+ installÃ© et dans le PATH
- [ ] Docker Desktop dÃ©marrÃ©
- [ ] DÃ©pendances installÃ©es (`pip install -r requirements.txt`)
- [ ] Dataset tÃ©lÃ©chargÃ© dans `data/raw/`
- [ ] ModÃ¨le entraÃ®nÃ© dans `models/checkpoints/`
- [ ] MLflow UI accessible (port 5000)
- [ ] Grafana/Prometheus up (docker-compose)

---

**Bonne soutenance! ğŸ“**
