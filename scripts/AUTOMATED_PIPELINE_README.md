# üöÄ Pipeline Automatis√© MLOps - Guide d'Utilisation

Ce guide explique comment utiliser le pipeline automatis√© qui se d√©clenche lorsque de nouvelles donn√©es sont d√©tect√©es par DVC.

## üìã Vue d'ensemble

Le pipeline automatis√© ex√©cute les √©tapes suivantes:

1. **D√©tection des changements DVC** - Surveille `dvc.lock` et les fichiers `.dvc`
2. **Ex√©cution du pipeline DVC** - Lance `dvc repro` pour pr√©parer les donn√©es et entra√Æner
3. **Enregistrement MLflow** - Les donn√©es et mod√®les sont automatiquement enregistr√©s dans MLflow
4. **Construction Docker** - Reconstruit l'image Docker avec le nouveau mod√®le
5. **D√©ploiement local** - Red√©ploie l'API avec Docker Compose

## üõ†Ô∏è Pr√©requis

```bash
# Installer les d√©pendances
pip install -r requirements.txt

# V√©rifier que DVC est install√©
dvc --version

# V√©rifier que Docker est install√©
docker --version
docker-compose --version
```

## üöÄ Utilisation

### Option 1: Ex√©cution manuelle unique

Ex√©cuter le pipeline une fois:

```bash
# Depuis la racine du projet
python scripts/run_automated_pipeline.py
```

Options disponibles:
```bash
# Forcer l'ex√©cution m√™me sans changements DVC
python scripts/run_automated_pipeline.py --force

# Ignorer certaines √©tapes
python scripts/run_automated_pipeline.py --skip-dvc --skip-docker

# Utiliser un fichier de config diff√©rent
python scripts/run_automated_pipeline.py --config my_config.yaml
```

### Option 2: Surveillance continue (recommand√©)

D√©marrer la surveillance qui d√©clenche automatiquement le pipeline:

```bash
# Surveillance avec v√©rification toutes les 30 secondes (d√©faut)
python scripts/watch_and_trigger.py

# Personnaliser l'intervalle
python scripts/watch_and_trigger.py --interval 60
```

### Option 3: V√©rification manuelle des changements

V√©rifier si des changements DVC sont d√©tect√©s:

```bash
# V√©rification unique
python scripts/monitor_dvc_changes.py

# Mode surveillance continue
python scripts/monitor_dvc_changes.py --watch --interval 30
```

## üìä Flux de travail typique

### 1. Ajouter de nouvelles donn√©es

```bash
# Ajouter de nouvelles images dans data/raw/PlantVillage/
# Par exemple, ajouter un nouveau dossier de classe

# Ajouter les donn√©es √† DVC
dvc add data/raw/PlantVillage/NewClass

# Commit les changements
git add data/raw/PlantVillage/NewClass.dvc dvc.lock
git commit -m "Add new plant disease class data"
```

### 2. D√©clencher le pipeline

**Automatique (si surveillance active):**
- Le pipeline se d√©clenche automatiquement dans les 30 secondes

**Manuel:**
```bash
python scripts/run_automated_pipeline.py
```

### 3. V√©rifier les r√©sultats

```bash
# V√©rifier que le mod√®le est enregistr√© dans MLflow
# Ouvrir: http://localhost:5000

# V√©rifier que l'API fonctionne
curl http://localhost:8000/health

# V√©rifier les services Docker
docker-compose -f docker/docker-compose.yml ps
```

## üîç D√©tails des √©tapes

### √âtape 1: D√©tection DVC

Le script `monitor_dvc_changes.py` v√©rifie:
- Modifications de `dvc.lock` (indique de nouvelles donn√©es)
- Modifications de `dvc.yaml` (indique un pipeline modifi√©)
- Modifications des fichiers `.dvc` dans `data/`

### √âtape 2: Pipeline DVC

Ex√©cute `dvc repro` qui lance:
- `prepare_data`: Pr√©paration et division des donn√©es
- `train`: Entra√Ænement du mod√®le
- `evaluate`: √âvaluation du mod√®le
- `export_model`: Export vers `models/production/`

### √âtape 3: MLflow

Le script `src/train.py` enregistre automatiquement:
- Param√®tres d'entra√Ænement
- M√©triques (accuracy, loss, etc.)
- Artifacts (mod√®le, graphiques)
- Mod√®le dans le Model Registry

### √âtape 4: Construction Docker

L'image Docker est reconstruite avec:
- Le nouveau mod√®le depuis `models/production/model.ckpt`
- Le code source mis √† jour
- Les d√©pendances n√©cessaires

### √âtape 5: D√©ploiement

Docker Compose:
- Arr√™te les services existants
- Reconstruit l'image API
- Red√©marre tous les services (API, MLflow, Prometheus, Grafana)

## üìù Configuration

Le pipeline utilise `config.yaml` pour:
- Chemins des donn√©es et mod√®les
- Configuration MLflow
- Configuration Docker
- Param√®tres d'entra√Ænement

## üêõ D√©pannage

### Le pipeline ne d√©tecte pas les changements

```bash
# V√©rifier manuellement
python scripts/monitor_dvc_changes.py

# Forcer l'ex√©cution
python scripts/run_automated_pipeline.py --force
```

### Erreur lors de l'ex√©cution DVC

```bash
# V√©rifier que DVC est initialis√©
dvc status

# V√©rifier les d√©pendances
dvc dag

# Ex√©cuter manuellement
dvc repro
```

### Erreur lors de la construction Docker

```bash
# V√©rifier que le mod√®le existe
ls -lh models/production/model.ckpt

# Construire manuellement
docker build -f docker/Dockerfile.inference -t plant-disease-mlops:latest .
```

### L'API ne d√©marre pas

```bash
# V√©rifier les logs
docker-compose -f docker/docker-compose.yml logs plant-disease-api

# V√©rifier le health check
curl http://localhost:8000/health

# Red√©marrer les services
docker-compose -f docker/docker-compose.yml restart
```

## üìä Monitoring

Une fois le pipeline ex√©cut√©, vous pouvez acc√©der √†:

- **API**: http://localhost:8000
  - Documentation: http://localhost:8000/docs
  - Health: http://localhost:8000/health
  - M√©triques: http://localhost:8000/metrics

- **MLflow**: http://localhost:5000
  - Exp√©riences et runs
  - Model Registry
  - M√©triques et graphiques

- **Grafana**: http://localhost:3000
  - Login: admin/admin
  - Dashboards de monitoring

- **Prometheus**: http://localhost:9091
  - M√©triques brutes
  - Requ√™tes PromQL

## üîÑ Workflow complet

```bash
# 1. D√©marrer la surveillance (dans un terminal)
python scripts/watch_and_trigger.py

# 2. Dans un autre terminal, ajouter de nouvelles donn√©es
dvc add data/raw/PlantVillage/NewClass
git add data/raw/PlantVillage/NewClass.dvc dvc.lock
git commit -m "Add new data"

# 3. Le pipeline se d√©clenche automatiquement!
# V√©rifier les logs dans le premier terminal

# 4. Tester la nouvelle API
curl -X POST http://localhost:8000/predict \
  -F "file=@test_image.jpg"
```

## üìö Scripts disponibles

| Script | Description |
|--------|-------------|
| `monitor_dvc_changes.py` | Surveille les changements DVC |
| `run_automated_pipeline.py` | Ex√©cute le pipeline complet |
| `watch_and_trigger.py` | Surveillance continue + d√©clenchement automatique |

## ‚úÖ Checklist

Avant d'utiliser le pipeline automatis√©:

- [ ] DVC est install√© et initialis√©
- [ ] Docker et Docker Compose sont install√©s
- [ ] MLflow est accessible (http://localhost:5000)
- [ ] Les donn√©es sont dans `data/raw/`
- [ ] Le fichier `config.yaml` est configur√©
- [ ] Les d√©pendances Python sont install√©es

## üéØ Prochaines √©tapes

Une fois le pipeline fonctionnel:

1. Configurer un remote DVC (Google Drive, S3, etc.)
2. Ajouter des notifications (email, Slack) lors des entra√Ænements
3. Configurer des seuils de qualit√© pour accepter/rejeter les mod√®les
4. Ajouter des tests automatiques avant le d√©ploiement
5. Int√©grer avec CI/CD (GitHub Actions, GitLab CI)

---

**üí° Astuce**: Pour un d√©veloppement plus rapide, utilisez `--skip-docker` et `--skip-deploy` pour tester uniquement l'entra√Ænement.

