#!/usr/bin/env python3
"""
Script pour ex√©cuter le pipeline complet d'entra√Ænement MLOps.
"""

import os
import sys
import argparse
import logging
from pathlib import Path

# Ajouter le r√©pertoire src au path
sys.path.append(str(Path(__file__).parent.parent / "src"))

from data_preprocessing import DataPreprocessor
from models import create_model
from train import train_model

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def run_training_pipeline(dataset_path, model_type="cnn", config_path="config.yaml"):
    """
    Ex√©cute le pipeline complet d'entra√Ænement.

    Args:
        dataset_path (str): Chemin vers le dataset
        model_type (str): Type de mod√®le ('cnn' ou 'vit')
        config_path (str): Chemin vers la configuration
    """
    logger.info("üöÄ D√©marrage du pipeline MLOps de d√©tection de maladies de plantes")

    try:
        # 1. Pr√©paration des donn√©es
        logger.info("üìä √âtape 1: Pr√©paration des donn√©es")
        preprocessor = DataPreprocessor(config_path)

        if not os.path.exists(dataset_path):
            raise FileNotFoundError(f"Dataset non trouv√©: {dataset_path}")

        # Cr√©er les DataLoaders
        data_result = preprocessor.create_data_loaders(dataset_path)
        logger.info(f"‚úÖ Donn√©es pr√©par√©es: {data_result['num_classes']} classes trouv√©es")

        # 2. Entra√Ænement du mod√®le
        logger.info("ü§ñ √âtape 2: Entra√Ænement du mod√®le")
        model, trainer = train_model(model_type, dataset_path, config_path)
        logger.info("‚úÖ Entra√Ænement termin√©")

        # 3. √âvaluation
        logger.info("üìà √âtape 3: √âvaluation du mod√®le")
        # L'√©valuation est d√©j√† faite dans train_model

        logger.info("üéâ Pipeline d'entra√Ænement termin√© avec succ√®s!")

        return model, trainer

    except Exception as e:
        logger.error(f"‚ùå Erreur dans le pipeline: {str(e)}")
        raise

def main():
    parser = argparse.ArgumentParser(description="Pipeline d'entra√Ænement MLOps")
    parser.add_argument(
        "--dataset",
        type=str,
        required=True,
        help="Chemin vers le dataset PlantVillage"
    )
    parser.add_argument(
        "--model",
        type=str,
        choices=['cnn', 'vit'],
        default='cnn',
        help="Type de mod√®le √† entra√Æner"
    )
    parser.add_argument(
        "--config",
        type=str,
        default="config.yaml",
        help="Chemin vers le fichier de configuration"
    )

    args = parser.parse_args()

    # V√©rifier que le dataset existe
    if not os.path.exists(args.dataset):
        logger.error(f"‚ùå Dataset non trouv√©: {args.dataset}")
        logger.info("üí° T√©l√©chargez le dataset PlantVillage depuis Kaggle:")
        logger.info("   https://www.kaggle.com/datasets/emmarex/plantdisease")
        sys.exit(1)

    try:
        run_training_pipeline(args.dataset, args.model, args.config)
    except Exception as e:
        logger.error(f"‚ùå √âchec du pipeline: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()
