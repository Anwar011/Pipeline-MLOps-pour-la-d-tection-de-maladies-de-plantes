# ===========================================
# MLOps Pipeline - WSL Self-Hosted Runner
# ===========================================
# ExÃ©cute sur WSL avec accÃ¨s aux donnÃ©es locales

name: MLOps Pipeline (WSL)

on:
  workflow_dispatch:
    inputs:
      model_type:
        description: 'Model type to train'
        required: false
        default: 'cnn'
        type: choice
        options:
          - cnn
          - vit

env:
  DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
  DOCKER_IMAGE_API: ${{ secrets.DOCKER_USERNAME }}/plant-disease-api
  MODEL_TYPE: ${{ github.event.inputs.model_type || 'cnn' }}

jobs:
  # ============================================
  # Train on WSL Self-Hosted Runner
  # ============================================
  train-wsl:
    name: ðŸ§  Train Model (WSL)
    runs-on: self-hosted
    
    outputs:
      model_version: ${{ steps.train.outputs.model_version }}
      
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ Setup Python Environment
        shell: wsl-bash {0}
        run: |
          echo "Python version:"
          python3 --version
          echo "Installing dependencies..."
          pip3 install -r requirements-train.txt

      - name: ðŸš€ Start MLflow Server
        shell: wsl-bash {0}
        run: |
          echo "Starting MLflow and monitoring services..."
          cd docker
          docker-compose up -d mlflow-server
          
          # Wait for MLflow to be ready
          echo "Waiting for MLflow server to start..."
          sleep 10
          
          # Verify MLflow is running
          docker-compose ps
          
          echo "âœ… MLflow server ready at http://localhost:5000"

      - name: ðŸ§  Run Training
        id: train
        shell: wsl-bash {0}
        run: |
          echo "ðŸš€ Starting training on WSL..."
          
          # Verify data exists
          echo "Checking data..."
          ls -la data/raw/PlantVillage/ | head -5
          
          # Create directories
          mkdir -p models/production mlruns metrics plots
          
          # Set environment
          export PYTHONPATH=$(pwd)
          export MLFLOW_TRACKING_URI="http://localhost:5000"
          
          # Run training
          echo "Starting training with model: ${{ env.MODEL_TYPE }}"
          echo "MLflow tracking at: http://localhost:5000"
          python3 src/train.py \
            --model ${{ env.MODEL_TYPE }} \
            --dataset data/raw/PlantVillage \
            --config config.yaml
          
          # Generate model version
          MODEL_VERSION="v$(date +%Y%m%d%H%M%S)"
          echo "model_version=$MODEL_VERSION" >> $GITHUB_OUTPUT
          
          echo "âœ… Training complete! Model version: $MODEL_VERSION"
          echo "ðŸ“Š View results at http://localhost:5000"

      - name: ðŸ“¤ Upload Model
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: |
            models/
            metrics/
            plots/

  # ============================================
  # Build API Image (on GitHub-hosted runner)
  # ============================================
  build-api:
    name: ðŸ³ Build API Image
    runs-on: ubuntu-latest
    needs: train-wsl
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ“¥ Download Trained Model
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: ./

      - name: ðŸ“‹ Verify Model
        run: |
          echo "Checking model artifacts..."
          ls -la models/production/ || echo "No production folder"
          ls -la models/checkpoints/ || echo "No checkpoints"
          
          # Copy best checkpoint to production if needed
          if [ ! -f models/production/model.ckpt ]; then
            BEST=$(find models/checkpoints -name "*.ckpt" 2>/dev/null | head -1)
            if [ -n "$BEST" ]; then
              mkdir -p models/production
              cp "$BEST" models/production/model.ckpt
              echo "âœ… Copied $BEST to production"
            fi
          fi
          
          echo "Production model:"
          ls -lh models/production/

      - name: ðŸ”§ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: ðŸ”‘ Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: ðŸ—ï¸ Build and Push API Image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile.inference
          push: true
          tags: |
            ${{ env.DOCKER_IMAGE_API }}:${{ needs.train-wsl.outputs.model_version }}
            ${{ env.DOCKER_IMAGE_API }}:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            MODEL_VERSION=${{ needs.train-wsl.outputs.model_version }}

      - name: âœ… Summary
        run: |
          echo "# ðŸŒ± Pipeline Complete!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## âœ… Training Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Model Version**: \`${{ needs.train-wsl.outputs.model_version }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Model Type**: \`${{ env.MODEL_TYPE }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ³ Docker Image" >> $GITHUB_STEP_SUMMARY
          echo "- **Image**: \`${{ env.DOCKER_IMAGE_API }}:latest\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Version**: \`${{ env.DOCKER_IMAGE_API }}:${{ needs.train-wsl.outputs.model_version }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ“Š MLflow" >> $GITHUB_STEP_SUMMARY
          echo "View training results at: http://localhost:5000" >> $GITHUB_STEP_SUMMARY
